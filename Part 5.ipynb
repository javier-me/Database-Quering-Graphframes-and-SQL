{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naDOrDAVAFk3"
   },
   "source": [
    "## 5. Politicians that are affiliated with a right-wing party\n",
    "\n",
    "We are looking for all connections of the form `polician -> party`, where party is a right-wing party and politicians are defined above. If one politician is associated with several right wing parties, you may count them several times.\n",
    "\n",
    "Use `'<isAffiliatedTo>'` to find membership in organisations and `'<wikicat_Right-wing_parties>'` for right-wing parties organisations.\n",
    "\n",
    "There are multiple ways to do this.\n",
    "\n",
    "Please sort the output alphabetically by the person (politician) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After having looked at the head of the file in the terminal, one can see that there is no header for the columns\n",
    "# so we'll have to create the schema ourselves. Also, the first line is an explanation of what the database contains,\n",
    "# which has to be removed before converting it into a df, so we'll upload the data to an RDD to do that removal\n",
    "# with the following function:\n",
    "def remove_first(itr_index, itr):\n",
    "    return iter(list(itr)[1:]) if itr_index == 0 else itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data to an RDD and remove first line\n",
    "file = sc.textFile(\"/yago/yagoFacts.tsv\")\n",
    "data = file.mapPartitionsWithIndex(remove_first) # Maybe this is smarter: rdd.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by columns\n",
    "rdd_map = data.map(lambda x: x.split(\"\\t\"))   \n",
    "#rdd_map.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already seen the data and datatypes it contains, because there's no header describing the dataset\n",
    "# we create a schema\n",
    "schema = StructType([\n",
    "                StructField(\"id\",StringType()),\n",
    "                StructField(\"subject\", StringType()),\n",
    "                StructField(\"predicate\", StringType()),\n",
    "                StructField(\"object\", StringType()),\n",
    "                StructField(\"value\", StringType())#DoubleType\n",
    "                    ])\n",
    "# It didn't work with the value as a DoubleType, so we'll create it with that column as a string\n",
    "# and change the datatype afterwards\n",
    "df = sqlContext.createDataFrame(rdd_map, schema)\n",
    "#df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change value Datatype\n",
    "df = df.withColumn(\"value\", df[\"value\"].cast(DoubleType()))\n",
    "#df.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the Transitive Type Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile(\"/yago/yagoTransitiveType.tsv\")\n",
    "data2 = file.mapPartitionsWithIndex(remove_first) # Maybe this is smarter:\n",
    "#data = file.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])\n",
    "rdd_map2 = data2.map(lambda x: x.split(\"\\t\"))   \n",
    "schema = StructType([\n",
    "                StructField(\"id\",StringType()),\n",
    "                StructField(\"subject\", StringType()),\n",
    "                StructField(\"predicate\", StringType()),\n",
    "                StructField(\"object\", StringType()),\n",
    "                StructField(\"value\", StringType())#DoubleType\n",
    "                    ])\n",
    "# It didn't work with the value as a DoubleType, so we'll create it with that column as a string\n",
    "# and change the datatype afterwards\n",
    "df_subclasses = sqlContext.createDataFrame(rdd_map2, schema)\n",
    "df_subclasses = df_subclasses.withColumn(\"value\", df_subclasses[\"value\"].cast(DoubleType()))\n",
    "#df_subclasses.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import graphframes\n",
    "from graphframes import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertices_edges_split(df, condition1):\n",
    "    sub = df.filter(condition1).select(\"subject\").withColumnRenamed(\"subject\",\"id\")\n",
    "    obj = df.filter(condition1).select(\"object\").withColumnRenamed(\"object\",\"id\")\n",
    "    v = sub.union(obj).distinct()\n",
    "    e = df.filter(condition1).select(\"subject\",\"object\",\"predicate\")\\\n",
    "    .withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\").withColumnRenamed(\"predicate\",\"pred\")\n",
    "    return v, e\n",
    "\n",
    "def vertices_edges_split2(df, condition1, condition2):\n",
    "    sub = df.filter(condition1).filter(condition2).select(\"subject\").withColumnRenamed(\"subject\",\"id\")\n",
    "    obj = df.filter(condition1).filter(condition2).select(\"object\").withColumnRenamed(\"object\",\"id\")\n",
    "    v = sub.union(obj).distinct()\n",
    "    e = df.filter(condition1).select(\"subject\",\"object\",\"predicate\")\\\n",
    "    .withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\").withColumnRenamed(\"predicate\",\"pred\")\n",
    "    return v, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = df_subclasses.select(\"subject\", \"object\", \"predicate\").filter(\"object = '<wordnet_politician_110450303>'\")\\\n",
    ".filter(\"predicate = 'rdf:type'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df\")\n",
    "df_subclasses.createOrReplaceTempView(\"df_subclasses\")\n",
    "politicians.createOrReplaceTempView(\"politicians\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliated_politicians = spark.sql(\"SELECT p.subject AS politician, p.object AS pol_cat, p.predicate AS pol_pred, \\\n",
    "d.object AS party, d.predicate AS affiliated_to \\\n",
    "FROM politicians p JOIN df d ON p.subject = d.subject \\\n",
    "WHERE d.predicate = '<isAffiliatedTo>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliated_politicians.createOrReplaceTempView(\"affiliated_politicians\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_wing = df_subclasses.select(\"subject\", \"object\", \"predicate\").filter(\"object = '<wikicat_Right-wing_parties>'\")\\\n",
    ".filter(\"predicate = 'rdf:type'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_wing.createOrReplaceTempView(\"right_wing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians_right_wing = spark.sql(\"SELECT p.politician, p.pol_cat, p.pol_pred, p.party, p.affiliated_to, \\\n",
    "r.object AS rw_obj, r.predicate AS rw_pred \\\n",
    "FROM affiliated_politicians p JOIN right_wing r ON p.party = r.subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertices_edges_split2(df, subject, object1, predicate1, object2, predicate2, object3, predicate3):\n",
    "    sub = df.select(subject).withColumnRenamed(subject, \"id\") #politician\n",
    "    obj1 = df.select(object1).withColumnRenamed(object1, \"id\") #pol_cat\n",
    "    obj2 = df.select(object2).withColumnRenamed(object2, \"id\") #party\n",
    "    obj3 = df.select(object3).withColumnRenamed(object3, \"id\") #rw_obj\n",
    "    v = sub.union(obj1).union(obj2).union(obj3).distinct()\n",
    "    \n",
    "    e_pol = df.select(subject, object1, predicate1)\\\n",
    "    .withColumnRenamed(subject, \"src\").withColumnRenamed(object1, \"dst\" ).withColumnRenamed(predicate1, \"pred\")\n",
    "    e_par = df.select(subject, object2, predicate2)\\\n",
    "    .withColumnRenamed(subject, \"src\").withColumnRenamed(object2, \"dst\").withColumnRenamed(predicate2, \"pred\")\n",
    "    e_rw = df.select(object2, object3, predicate3)\\\n",
    "    .withColumnRenamed(object2, \"src\").withColumnRenamed(object3, \"dst\").withColumnRenamed(predicate3, \"pred\")\n",
    "    e = e_pol.union(e_par).union(e_rw).distinct()\n",
    "    \n",
    "    return v, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, e = vertices_edges_split2(politicians_right_wing, \\\n",
    "                             \"politician\", \"pol_cat\", \"pol_pred\", \"party\", \"affiliated_to\", \"rw_obj\", \"rw_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginning = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                   a|                   e|                   c|                  e2|                   p|                  e3|                   r|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[<A.N.M._Ehsanul_...|[<A.N.M._Ehsanul_...|[<wordnet_politic...|[<A.N.M._Ehsanul_...|[<Bangladesh_Nati...|[<Bangladesh_Nati...|[<wikicat_Right-w...|\n",
      "|[<A._A._Wijethunga>]|[<A._A._Wijethung...|[<wordnet_politic...|[<A._A._Wijethung...|[<United_National...|[<United_National...|[<wikicat_Right-w...|\n",
      "|    [<A._B._Colton>]|[<A._B._Colton>, ...|[<wordnet_politic...|[<A._B._Colton>, ...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|   [<A._C._Clemons>]|[<A._C._Clemons>,...|[<wordnet_politic...|[<A._C._Clemons>,...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|     [<A._C._Gibbs>]|[<A._C._Gibbs>, <...|[<wordnet_politic...|[<A._C._Gibbs>, <...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|    [<A._C._Hamlin>]|[<A._C._Hamlin>, ...|[<wordnet_politic...|[<A._C._Hamlin>, ...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|[<A._Clifford_Jon...|[<A._Clifford_Jon...|[<wordnet_politic...|[<A._Clifford_Jon...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|   [<A._Dean_Jeffs>]|[<A._Dean_Jeffs>,...|[<wordnet_politic...|[<A._Dean_Jeffs>,...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|[<A._F._M._Ahsanu...|[<A._F._M._Ahsanu...|[<wordnet_politic...|[<A._F._M._Ahsanu...|[<Jatiya_Party_(E...|[<Jatiya_Party_(E...|[<wikicat_Right-w...|\n",
      "|     [<A._G._Crowe>]|[<A._G._Crowe>, <...|[<wordnet_politic...|[<A._G._Crowe>, <...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|[<A._Homer_Byingt...|[<A._Homer_Byingt...|[<wordnet_politic...|[<A._Homer_Byingt...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|[<A._Homer_Byingt...|[<A._Homer_Byingt...|[<wordnet_politic...|[<A._Homer_Byingt...|[<National_Union_...|[<National_Union_...|[<wikicat_Right-w...|\n",
      "|[<A._J._M._Muzamm...|[<A._J._M._Muzamm...|[<wordnet_politic...|[<A._J._M._Muzamm...|[<United_National...|[<United_National...|[<wikicat_Right-w...|\n",
      "|  [<A._J._McNamara>]|[<A._J._McNamara>...|[<wordnet_politic...|[<A._J._McNamara>...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|[<A._J._Ranasinghe>]|[<A._J._Ranasingh...|[<wordnet_politic...|[<A._J._Ranasingh...|[<United_National...|[<United_National...|[<wikicat_Right-w...|\n",
      "|[<A._K._A._Firoze...|[<A._K._A._Firoze...|[<wordnet_politic...|[<A._K._A._Firoze...|[<Bangladesh_Nati...|[<Bangladesh_Nati...|[<wikicat_Right-w...|\n",
      "|     [<A._K._Patel>]|[<A._K._Patel>, <...|[<wordnet_politic...|[<A._K._Patel>, <...|[<Bharatiya_Janat...|[<Bharatiya_Janat...|[<wikicat_Right-w...|\n",
      "|[<A._Linwood_Holt...|[<A._Linwood_Holt...|[<wordnet_politic...|[<A._Linwood_Holt...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "|     [<A._M._Starr>]|[<A._M._Starr>, <...|[<wordnet_politic...|[<A._M._Starr>, <...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "| [<A._Piatt_Andrew>]|[<A._Piatt_Andrew...|[<wordnet_politic...|[<A._Piatt_Andrew...|[<Republican_Part...|[<Republican_Part...|[<wikicat_Right-w...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[e]->(c); (a)-[e2]->(p); (p)-[e3]->(r) \").filter(\"c.id = '<wordnet_politician_110450303>'\")\\\n",
    ".filter(\"e2.pred = '<isAffiliatedTo>'\").filter(\"r.id = '<wikicat_Right-wing_parties>'\").sort(\"a\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 09:40:13 \n",
      " Ended at 11:49:16\n"
     ]
    }
   ],
   "source": [
    "ending = datetime.now()\n",
    "beginning_time = beginning.strftime(\"%H:%M:%S\")\n",
    "ending_time = ending.strftime(\"%H:%M:%S\")\n",
    "\n",
    "print(\"Started at {} \\n Ended at {}\".format(beginning_time, ending_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
