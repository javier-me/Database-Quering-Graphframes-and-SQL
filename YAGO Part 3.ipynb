{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Nobel Laureates who are also Writers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEoKKWjTAFk2"
   },
   "source": [
    "Tags for nobel prizes look like these: `'<Nobel_Prize_in_Chemistry>`, `<Nobel_Prize_in_Physics>'`, `<Nobel_Prize>` or `<Nobel_Prize>` etc.\n",
    "We are also counting this one: `'<Nobel_Memorial_Prize_in_Economic_Sciences>'`.\n",
    "\n",
    "The tag for writers is `'<wordnet_writer_110794014>'`.\n",
    "\n",
    "You will need to use `'<hasWonPrize>'` as a predicate.\n",
    "\n",
    "Please sort the output alphabetically by the person column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After having looked at the head of the file in the terminal, one can see that there is no header for the columns\n",
    "# so we'll have to create the schema ourselves. Also, the first line is an explanation of what the database contains,\n",
    "# which has to be removed before converting it into a df, so we'll upload the data to an RDD to do that removal\n",
    "# with the following function:\n",
    "def remove_first(itr_index, itr):\n",
    "    return iter(list(itr)[1:]) if itr_index == 0 else itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data to an RDD and remove first line\n",
    "file = sc.textFile(\"/yago/yagoFacts.tsv\")\n",
    "data = file.mapPartitionsWithIndex(remove_first) # Maybe this is smarter: rdd.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by columns\n",
    "rdd_map = data.map(lambda x: x.split(\"\\t\"))   \n",
    "#rdd_map.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already seen the data and datatypes it contains, because there's no header describing the dataset\n",
    "# we create a schema\n",
    "schema = StructType([\n",
    "                StructField(\"id\",StringType()),\n",
    "                StructField(\"subject\", StringType()),\n",
    "                StructField(\"predicate\", StringType()),\n",
    "                StructField(\"object\", StringType()),\n",
    "                StructField(\"value\", StringType())#DoubleType\n",
    "                    ])\n",
    "# It didn't work with the value as a DoubleType, so we'll create it with that column as a string\n",
    "# and change the datatype afterwards\n",
    "df = sqlContext.createDataFrame(rdd_map, schema)\n",
    "#df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change value Datatype\n",
    "df = df.withColumn(\"value\", df[\"value\"].cast(DoubleType()))\n",
    "#df.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the Transitive Type Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile(\"/yago/yagoTransitiveType.tsv\")\n",
    "data2 = file.mapPartitionsWithIndex(remove_first) # Maybe this is smarter:\n",
    "#data = file.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])\n",
    "rdd_map2 = data2.map(lambda x: x.split(\"\\t\"))   \n",
    "schema = StructType([\n",
    "                StructField(\"id\",StringType()),\n",
    "                StructField(\"subject\", StringType()),\n",
    "                StructField(\"predicate\", StringType()),\n",
    "                StructField(\"object\", StringType()),\n",
    "                StructField(\"value\", StringType())#DoubleType\n",
    "                    ])\n",
    "# It didn't work with the value as a DoubleType, so we'll create it with that column as a string\n",
    "# and change the datatype afterwards\n",
    "df_subclasses = sqlContext.createDataFrame(rdd_map2, schema)\n",
    "df_subclasses = df_subclasses.withColumn(\"value\", df_subclasses[\"value\"].cast(DoubleType()))\n",
    "#df_subclasses.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import graphframes\n",
    "from graphframes import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Separate Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobels = df.select(\"subject\", \"object\", \"predicate\").filter(\"predicate = '<hasWonPrize>'\")\\\n",
    ".filter(\"object = '<Nobel_Prize_in_Chemistry>' OR object = '<Nobel_Prize_in_Physics>' \\\n",
    "OR object = '<Nobel_Prize_in_Literature>' OR object = '<Nobel_Prize>' \\\n",
    "OR object = '<Nobel_Memorial_Prize_in_Economic_Sciences>' OR object = '<Nobel_Prize_in_Physiology_or_Medicine>'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 07:23:02 \n",
      " Ended at 07:23:02\n",
      "('Took', '-1 day, 23:59:59.957057')\n"
     ]
    }
   ],
   "source": [
    "writers = df_subclasses.select(\"subject\", \"object\", \"predicate\")\\\n",
    ".filter(\"object = '<wordnet_writer_110794014>'\").filter(\"predicate = 'rdf:type'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobels.createOrReplaceTempView(\"nobels\")\n",
    "writers.createOrReplaceTempView(\"writers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobel_writers = spark.sql(\"SELECT n.subject, n.object, n.predicate, w.object AS writer_obj, w.predicate AS writer_pred \\\n",
    "FROM nobels n JOIN writers w ON n.subject = w.subject\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Entries and Count are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+--------------------+-----------+\n",
      "|             subject|              object|    predicate|          writer_obj|writer_pred|\n",
      "+--------------------+--------------------+-------------+--------------------+-----------+\n",
      "|    <Grazia_Deledda>|<Nobel_Prize_in_L...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "|        <John_Hicks>|<Nobel_Memorial_P...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "|<Aleksandr_Solzhe...|<Nobel_Prize_in_L...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "|       <W._B._Yeats>|<Nobel_Prize_in_L...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "|        <Lev_Landau>|<Nobel_Prize_in_P...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "| <Thomas_J._Sargent>|<Nobel_Memorial_P...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "| <Tjalling_Koopmans>|<Nobel_Memorial_P...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "|        <Henry_Yule>|<Nobel_Prize_in_L...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "|<J._Michael_Koste...|<Nobel_Prize_in_P...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "|   <Nadine_Gordimer>|<Nobel_Prize_in_L...|<hasWonPrize>|<wordnet_writer_1...|   rdf:type|\n",
      "+--------------------+--------------------+-------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "215\n",
      "Started at 17:47:26 \n",
      " Ended at 18:32:19\n",
      "('Took', '-1 day, 23:15:06.715016')\n"
     ]
    }
   ],
   "source": [
    "beginning = datetime.now()\n",
    "\n",
    "nobel_writers.show(10)\n",
    "print(nobel_writers.count())\n",
    "\n",
    "ending = datetime.now()\n",
    "beginning_time = beginning.strftime(\"%H:%M:%S\")\n",
    "ending_time = ending.strftime(\"%H:%M:%S\")\n",
    "\n",
    "print(\"Started at {} \\n Ended at {}\".format(beginning_time, ending_time))\n",
    "elapsed = (beginning-ending)\n",
    "print(\"Took\", str(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vertex, Edges and Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_nw = nobel_writers.select(\"subject\").withColumnRenamed(\"subject\", \"id\")\\\n",
    ".union(nobel_writers.select(\"writer_obj\").withColumnRenamed(\"writer_obj\", \"id\"))\\\n",
    ".union(nobel_writers.select(\"object\").withColumnRenamed(\"object\", \"id\")).distinct()\n",
    "\n",
    "v_nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src', 'dst', 'pred']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_l = nobel_writers.select(\"subject\", \"object\", \"predicate\").withColumnRenamed(\"subject\", \"src\")\\\n",
    ".withColumnRenamed(\"object\", \"dst\").withColumnRenamed(\"predicate\", \"pred\")\n",
    "\n",
    "e_w = nobel_writers.select(\"subject\", \"writer_obj\", \"writer_pred\").withColumnRenamed(\"subject\", \"src\")\\\n",
    ".withColumnRenamed(\"writer_obj\", \"dst\").withColumnRenamed(\"writer_pred\", \"pred\")\n",
    "\n",
    "e_nw = e_w.union(e_l)\n",
    "e_nw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_nw = GraphFrame(v_nw, e_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphFrame(v:[id: string], e:[src: string, dst: string ... 1 more field])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_nw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                   a|                   e|                   b|                  e2|                   c|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[<Adrienne_Clarks...|[<Adrienne_Clarks...|[<wordnet_writer_...|[<Adrienne_Clarks...|[<Nobel_Prize_in_...|\n",
      "|    [<Albert_Camus>]|[<Albert_Camus>, ...|[<wordnet_writer_...|[<Albert_Camus>, ...|[<Nobel_Prize_in_...|\n",
      "| [<Albert_Einstein>]|[<Albert_Einstein...|[<wordnet_writer_...|[<Albert_Einstein...|[<Nobel_Prize_in_...|\n",
      "|[<Aleksandr_Solzh...|[<Aleksandr_Solzh...|[<wordnet_writer_...|[<Aleksandr_Solzh...|[<Nobel_Prize_in_...|\n",
      "|[<Alexander_Prokh...|[<Alexander_Prokh...|[<wordnet_writer_...|[<Alexander_Prokh...|[<Nobel_Prize_in_...|\n",
      "|[<Alexei_Alexeyev...|[<Alexei_Alexeyev...|[<wordnet_writer_...|[<Alexei_Alexeyev...|[<Nobel_Prize_in_...|\n",
      "|   [<Alexis_Carrel>]|[<Alexis_Carrel>,...|[<wordnet_writer_...|[<Alexis_Carrel>,...|[<Nobel_Prize_in_...|\n",
      "|  [<Alfred_Kastler>]|[<Alfred_Kastler>...|[<wordnet_writer_...|[<Alfred_Kastler>...|[<Nobel_Prize_in_...|\n",
      "|     [<Alice_Munro>]|[<Alice_Munro>, <...|[<wordnet_writer_...|[<Alice_Munro>, <...|[<Nobel_Prize_in_...|\n",
      "|   [<Alvin_E._Roth>]|[<Alvin_E._Roth>,...|[<wordnet_writer_...|[<Alvin_E._Roth>,...|[<Nobel_Memorial_...|\n",
      "|   [<Alvin_Toffler>]|[<Alvin_Toffler>,...|[<wordnet_writer_...|[<Alvin_Toffler>,...|[<Nobel_Prize_in_...|\n",
      "|     [<Amartya_Sen>]|[<Amartya_Sen>, <...|[<wordnet_writer_...|[<Amartya_Sen>, <...|[<Nobel_Memorial_...|\n",
      "|  [<Anatole_France>]|[<Anatole_France>...|[<wordnet_writer_...|[<Anatole_France>...|[<Nobel_Prize_in_...|\n",
      "|      [<André_Gide>]|[<André_Gide>, <w...|[<wordnet_writer_...|[<André_Gide>, <N...|[<Nobel_Prize_in_...|\n",
      "| [<Arthur_Kornberg>]|[<Arthur_Kornberg...|[<wordnet_writer_...|[<Arthur_Kornberg...|[<Nobel_Prize_in_...|\n",
      "|     [<Aziz_Sancar>]|[<Aziz_Sancar>, <...|[<wordnet_writer_...|[<Aziz_Sancar>, <...|[<Nobel_Prize_in_...|\n",
      "|    [<Bert_Sakmann>]|[<Bert_Sakmann>, ...|[<wordnet_writer_...|[<Bert_Sakmann>, ...|[<Nobel_Prize_in_...|\n",
      "|[<Bertrand_Russell>]|[<Bertrand_Russel...|[<wordnet_writer_...|[<Bertrand_Russel...|[<Nobel_Prize_in_...|\n",
      "|[<Bjørnstjerne_Bj...|[<Bjørnstjerne_Bj...|[<wordnet_writer_...|[<Bjørnstjerne_Bj...|[<Nobel_Prize_in_...|\n",
      "|       [<Bob_Dylan>]|[<Bob_Dylan>, <wo...|[<wordnet_writer_...|[<Bob_Dylan>, <No...|[<Nobel_Prize_in_...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Started at 07:23:29 \n",
      " Ended at 14:55:24\n",
      "('Took', '-1 day, 16:28:05.154907')\n"
     ]
    }
   ],
   "source": [
    "beginning = datetime.now()\n",
    "\n",
    "g_nw.find(\"(a)-[e]->(b); (a)-[e2]->(c)\").filter(\"b.id = '<wordnet_writer_110794014>'\")\\\n",
    ".filter(\"c.id = '<Nobel_Prize_in_Chemistry>' OR c.id = '<Nobel_Prize_in_Physics>' \\\n",
    "OR c.id = '<Nobel_Prize_in_Literature>' OR c.id = '<Nobel_Prize>' \\\n",
    "OR c.id = '<Nobel_Memorial_Prize_in_Economic_Sciences>' OR c.id = '<Nobel_Prize_in_Physiology_or_Medicine>'\")\\\n",
    ".sort(\"a\").show(20)\n",
    "\n",
    "\n",
    "ending = datetime.now()\n",
    "beginning_time = beginning.strftime(\"%H:%M:%S\")\n",
    "ending_time = ending.strftime(\"%H:%M:%S\")\n",
    "\n",
    "print(\"Started at {} \\n Ended at {}\".format(beginning_time, ending_time))\n",
    "elapsed = (beginning-ending)\n",
    "print(\"Took\", str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
