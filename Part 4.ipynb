{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Nobel prize winners who were born in the same city as their spouses \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OZpUAkkAFk2"
   },
   "source": [
    "You may find the predicate `'<isMarriedTo>'` useful to create a Dataframe of all mariages.\n",
    "Please also show the cities in which the Nobel laureates and their spouses were born.\n",
    "\n",
    "Please sort the output alphabetically by the person (prize winner) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After having looked at the head of the file in the terminal, one can see that there is no header for the columns\n",
    "# so we'll have to create the schema ourselves. Also, the first line is an explanation of what the database contains,\n",
    "# which has to be removed before converting it into a df, so we'll upload the data to an RDD to do that removal\n",
    "# with the following function:\n",
    "def remove_first(itr_index, itr):\n",
    "    return iter(list(itr)[1:]) if itr_index == 0 else itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data to an RDD and remove first line\n",
    "file = sc.textFile(\"/yago/yagoFacts.tsv\")\n",
    "data = file.mapPartitionsWithIndex(remove_first) # Maybe this is smarter: rdd.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by columns\n",
    "rdd_map = data.map(lambda x: x.split(\"\\t\"))   \n",
    "#rdd_map.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already seen the data and datatypes it contains, because there's no header describing the dataset\n",
    "# we create a schema\n",
    "schema = StructType([\n",
    "                StructField(\"id\",StringType()),\n",
    "                StructField(\"subject\", StringType()),\n",
    "                StructField(\"predicate\", StringType()),\n",
    "                StructField(\"object\", StringType()),\n",
    "                StructField(\"value\", StringType())#DoubleType\n",
    "                    ])\n",
    "# It didn't work with the value as a DoubleType, so we'll create it with that column as a string\n",
    "# and change the datatype afterwards\n",
    "df = sqlContext.createDataFrame(rdd_map, schema)\n",
    "#df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change value Datatype\n",
    "df = df.withColumn(\"value\", df[\"value\"].cast(DoubleType()))\n",
    "#df.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the Transitive Type Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile(\"/yago/yagoTransitiveType.tsv\")\n",
    "data2 = file.mapPartitionsWithIndex(remove_first) # Maybe this is smarter:\n",
    "#data = file.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])\n",
    "rdd_map2 = data2.map(lambda x: x.split(\"\\t\"))   \n",
    "schema = StructType([\n",
    "                StructField(\"id\",StringType()),\n",
    "                StructField(\"subject\", StringType()),\n",
    "                StructField(\"predicate\", StringType()),\n",
    "                StructField(\"object\", StringType()),\n",
    "                StructField(\"value\", StringType())#DoubleType\n",
    "                    ])\n",
    "# It didn't work with the value as a DoubleType, so we'll create it with that column as a string\n",
    "# and change the datatype afterwards\n",
    "df_subclasses = sqlContext.createDataFrame(rdd_map2, schema)\n",
    "df_subclasses = df_subclasses.withColumn(\"value\", df_subclasses[\"value\"].cast(DoubleType()))\n",
    "#df_subclasses.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import graphframes\n",
    "from graphframes import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df\")\n",
    "df_subclasses.createOrReplaceTempView(\"df_subclasses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nobel Laureates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "laureates = df.select(\"subject\", \"object\", \"predicate\").filter(\"predicate = '<hasWonPrize>' AND object = '<Nobel_Prize_in_Chemistry>' OR object = '<Nobel_Prize_in_Physics>' OR object = '<Nobel_Prize_in_Literature>' OR object = '<Nobel_Prize>' OR object = '<Nobel_Memorial_Prize_in_Economic_Sciences>' OR object = '<Nobel_Prize_in_Physiology_or_Medicine>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "laureates.createOrReplaceTempView(\"laureates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "born = df.select(\"subject\", \"object\", \"predicate\").filter(\"predicate = '<wasBornIn>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "born.createOrReplaceTempView(\"born\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nobels with Place of Birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "laureates_born = spark.sql(\"SELECT l.subject AS laureate, l.object AS nobel, l.predicate AS nobel_pred, \\\n",
    "b.object AS city, b.predicate AS city_pred \\\n",
    "FROM laureates l JOIN born b \\\n",
    "ON l.subject = b.subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laureate', 'nobel', 'nobel_pred', 'city', 'city_pred']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laureates_born.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "laureates_born.createOrReplaceTempView(\"laureates_born\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Nobels, Place of Birth, and Person married to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "laureates_born_married = spark.sql(\"SELECT l.laureate, l.nobel, l.nobel_pred, l.city, l.city_pred, \\\n",
    "d.object AS pers_married, d.predicate AS married_to_pred \\\n",
    "FROM laureates_born l JOIN df d ON l.laureate = d.subject \\\n",
    "WHERE d.predicate = '<isMarriedTo>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laureate',\n",
       " 'nobel',\n",
       " 'nobel_pred',\n",
       " 'city',\n",
       " 'city_pred',\n",
       " 'pers_married',\n",
       " 'married_to_pred']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laureates_born_married.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "laureates_born_married.createOrReplaceTempView(\"laureates_born_married\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to have married couples born is same city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "laureates_born_married_both = spark.sql(\"SELECT l.laureate, l.nobel, l.nobel_pred, l.city, l.city_pred, l.pers_married, \\\n",
    "l.married_to_pred \\\n",
    "FROM laureates_born_married l JOIN df d ON l.pers_married = d.subject \\\n",
    "WHERE d.predicate = '<wasBornIn>' AND l.city = d.object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#laureates_born_married_both.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vertex, edges and graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = laureates_born_married_both.select(\"laureate\").withColumnRenamed(\"laureate\", \"id\")\\\n",
    ".union(laureates_born_married_both.select(\"nobel\").withColumnRenamed(\"nobel\", \"id\"))\\\n",
    ".union(laureates_born_married_both.select(\"city\").withColumnRenamed(\"city\", \"id\"))\\\n",
    ".union(laureates_born_married_both.select(\"pers_married\").withColumnRenamed(\"pers_married\", \"id\")).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = laureates_born_married_both.select(\"laureate\", \"nobel\", \"nobel_pred\").withColumnRenamed(\"laureate\", \"src\")\\\n",
    ".withColumnRenamed(\"nobel\", \"dst\").withColumnRenamed(\"nobel_pred\", \"pred\")\\\n",
    ".union(laureates_born_married_both.select(\"laureate\", \"city\", \"city_pred\").withColumnRenamed(\"laureate\", \"src\")\\\n",
    ".withColumnRenamed(\"city\", \"dst\").withColumnRenamed(\"city_pred\", \"pred\"))\\\n",
    ".union(laureates_born_married_both.select(\"laureate\", \"pers_married\", \"married_to_pred\").withColumnRenamed(\"laureate\", \"src\")\\\n",
    ".withColumnRenamed(\"pers_married\", \"dst\").withColumnRenamed(\"married_to_pred\", \"pred\"))\\\n",
    ".union(laureates_born_married_both.select(\"pers_married\", \"city\", \"city_pred\").withColumnRenamed(\"pers_married\", \"src\")\\\n",
    ".withColumnRenamed(\"city\", \"dst\").withColumnRenamed(\"city_pred\", \"pred\")).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+\n",
      "|                   l|                  e1|                   n|                  e2|                   p|                  e3|                b|                   m|                  e4|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+\n",
      "|[<Carl_Ferdinand_...|[<Carl_Ferdinand_...|[<Nobel_Prize_in_...|[<Carl_Ferdinand_...|      [<Gerty_Cori>]|[<Carl_Ferdinand_...|       [<Prague>]|      [<Gerty_Cori>]|[<Gerty_Cori>, <P...|\n",
      "|[<Frédéric_Joliot...|[<Frédéric_Joliot...|[<Nobel_Prize_in_...|[<Frédéric_Joliot...|[<Irène_Joliot-Cu...|[<Frédéric_Joliot...|        [<Paris>]|[<Irène_Joliot-Cu...|[<Irène_Joliot-Cu...|\n",
      "|      [<Gerty_Cori>]|[<Gerty_Cori>, <N...|[<Nobel_Prize_in_...|[<Gerty_Cori>, <C...|[<Carl_Ferdinand_...|[<Gerty_Cori>, <P...|       [<Prague>]|[<Carl_Ferdinand_...|[<Carl_Ferdinand_...|\n",
      "|[<Irène_Joliot-Cu...|[<Irène_Joliot-Cu...|[<Nobel_Prize_in_...|[<Irène_Joliot-Cu...|[<Frédéric_Joliot...|[<Irène_Joliot-Cu...|        [<Paris>]|[<Frédéric_Joliot...|[<Frédéric_Joliot...|\n",
      "|[<Robert_Hofstadt...|[<Robert_Hofstadt...|[<Nobel_Prize_in_...|[<Robert_Hofstadt...|[<Douglas_Hofstad...|[<Robert_Hofstadt...|[<New_York_City>]|[<Douglas_Hofstad...|[<Douglas_Hofstad...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+\n",
      "\n",
      "Started at 02:21:17 \n",
      " Ended at 03:14:43\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(l)-[e1]->(n); (l)-[e2]->(p); (l)-[e3]->(b); (m)-[e4]->(b)\")\\\n",
    ".filter(\"e1.pred = '<hasWonPrize>'\").filter(\"e2.pred = '<isMarriedTo>'\")\\\n",
    ".filter(\"e3.pred = '<wasBornIn>'\").filter(\"e4.pred = '<wasBornIn>'\")\\\n",
    ".filter(\"l.id != m.id\").sort(\"l\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
